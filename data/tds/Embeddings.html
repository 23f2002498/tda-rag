<article class="markdown-section" id="main"><h2 id="embeddings-openai-and-local-models"><a class="anchor" data-id="embeddings-openai-and-local-models" href="#/embeddings?id=embeddings-openai-and-local-models"><span>Embeddings: OpenAI and Local Models</span></a></h2><p>Embedding models convert text into a list of numbers. These are like a map of text in numerical form. Each number represents a feature, and similar texts will have numbers close to each other. So, if the numbers are similar, the text they represent mean something similar.</p><p>This is useful because text similarity is important in many common problems:</p><ol><li><strong>Search</strong>. Find similar documents to a query.</li><li><strong>Classification</strong>. Classify text into categories.</li><li><strong>Clustering</strong>. Group similar items into clusters.</li><li><strong>Anomaly Detection</strong>. Find an unusual piece of text.</li></ol><p>You can run embedding models locally or using an API. Local models are better for privacy and cost. APIs are better for scale and quality.</p>
<div class="table-wrapper">
<table id="_9i49v1go6">
<thead><tr>
<th>Feature</th>
<th>Local Models</th>
<th>API</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Privacy</strong></td>
<td>High</td>
<td>Dependent on provider</td>
</tr>
<tr>
<td><strong>Cost</strong></td>
<td>High setup, low after that</td>
<td>Pay-as-you-go</td>
</tr>
<tr>
<td><strong>Scale</strong></td>
<td>Limited by local resources</td>
<td>Easily scales with demand</td>
</tr>
<tr>
<td><strong>Quality</strong></td>
<td>Varies by model</td>
<td>Typically high</td>
</tr>
</tbody>
</table>
</div><p>The <a href="https://huggingface.co/spaces/mteb/leaderboard" rel="noopener" target="_blank">Massive Text Embedding Benchmark (MTEB)</a> provides comprehensive comparisons of embedding models. These models are compared on several parameters, but here are some key ones to look at:</p><ol><li><strong>Rank</strong>. Higher ranked models have higher quality.</li><li><strong>Memory Usage</strong>. Lower is better (for similar ranks). It costs less and is faster to run.</li><li><strong>Embedding Dimensions</strong>. Lower is better. This is the number of numbers in the array. Smaller dimensions are cheaper to store.</li><li><strong>Max Tokens</strong>. Higher is better. This is the number of input tokens (words) the model can take in a <em>single</em> input.</li><li>Look for higher scores in the columns for Classification, Clustering, Summarization, etc. based on your needs.</li></ol><h3 id="local-embeddings"><a class="anchor" data-id="local-embeddings" href="#/embeddings?id=local-embeddings"><span>Local Embeddings</span></a></h3><p><a href="https://youtu.be/OATCgQtNX2o" rel="noopener" target="_blank"><img alt="Guide to Local Embeddings with Sentence Transformers" data-origin="https://i.ytimg.com/vi/OATCgQtNX2o/sddefault.jpg" src="https://i.ytimg.com/vi/OATCgQtNX2o/sddefault.jpg"/></a></p><p>Here’s a minimal example using a local embedding model:</p><pre class="language-python" data-lang="python" v-pre=""><code class="lang-python language-python"><span class="token comment"># /// script</span>
<span class="token comment"># requires-python = "==3.12"</span>
<span class="token comment"># dependencies = [</span>
<span class="token comment">#   "sentence-transformers",</span>
<span class="token comment">#   "httpx",</span>
<span class="token comment">#   "numpy",</span>
<span class="token comment"># ]</span>
<span class="token comment"># ///</span>

<span class="token keyword">from</span> sentence_transformers <span class="token keyword">import</span> SentenceTransformer
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

model <span class="token operator">=</span> SentenceTransformer<span class="token punctuation">(</span><span class="token string">'BAAI/bge-base-en-v1.5'</span><span class="token punctuation">)</span>  <span class="token comment"># A small, high quality model</span>

<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">embed</span><span class="token punctuation">(</span>text<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Get embedding vector for text using local model."""</span>
    <span class="token keyword">return</span> model<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">get_similarity</span><span class="token punctuation">(</span>text1<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> text2<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">float</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Calculate cosine similarity between two texts."""</span>
    emb1 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token keyword">await</span> embed<span class="token punctuation">(</span>text1<span class="token punctuation">)</span><span class="token punctuation">)</span>
    emb2 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token keyword">await</span> embed<span class="token punctuation">(</span>text2<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token builtin">float</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>emb1<span class="token punctuation">,</span> emb2<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>emb1<span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>emb2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token keyword">await</span> get_similarity<span class="token punctuation">(</span><span class="token string">"Apple"</span><span class="token punctuation">,</span> <span class="token string">"Orange"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token keyword">await</span> get_similarity<span class="token punctuation">(</span><span class="token string">"Apple"</span><span class="token punctuation">,</span> <span class="token string">"Lightning"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    <span class="token keyword">import</span> asyncio
    asyncio<span class="token punctuation">.</span>run<span class="token punctuation">(</span>main<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code><button class="docsify-copy-code-button"><span class="label">Copy to clipboard</span><span aria-hidden="hidden" class="error">Error</span><span aria-hidden="hidden" class="success">Copied</span><span aria-live="polite"></span></button></pre><p>Note the <code>get_similarity</code> function. It uses a <a href="https://en.wikipedia.org/wiki/Cosine_similarity" rel="noopener" target="_blank">Cosine Similarity</a> to calculate the similarity between two embeddings.</p><h3 id="openai-embeddings"><a class="anchor" data-id="openai-embeddings" href="#/embeddings?id=openai-embeddings"><span>OpenAI Embeddings</span></a></h3><p>For comparison, here’s how to use OpenAI’s API with direct HTTP calls. Replace the <code>embed</code> function in the earlier script:</p><pre class="language-python" data-lang="python" v-pre=""><code class="lang-python language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> httpx

<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">embed</span><span class="token punctuation">(</span>text<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Get embedding vector for text using OpenAI's API."""</span>
    <span class="token keyword">async</span> <span class="token keyword">with</span> httpx<span class="token punctuation">.</span>AsyncClient<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> client<span class="token punctuation">:</span>
        response <span class="token operator">=</span> <span class="token keyword">await</span> client<span class="token punctuation">.</span>post<span class="token punctuation">(</span>
            <span class="token string">"https://api.openai.com/v1/embeddings"</span><span class="token punctuation">,</span>
            headers<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"Authorization"</span><span class="token punctuation">:</span> <span class="token string-interpolation"><span class="token string">f"Bearer </span><span class="token interpolation"><span class="token punctuation">{</span>os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_KEY'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">}</span><span class="token punctuation">,</span>
            json<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"model"</span><span class="token punctuation">:</span> <span class="token string">"text-embedding-3-small"</span><span class="token punctuation">,</span> <span class="token string">"input"</span><span class="token punctuation">:</span> text<span class="token punctuation">}</span>
        <span class="token punctuation">)</span>
        <span class="token keyword">return</span> response<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">"data"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"embedding"</span><span class="token punctuation">]</span></code><button class="docsify-copy-code-button"><span class="label">Copy to clipboard</span><span aria-hidden="hidden" class="error">Error</span><span aria-hidden="hidden" class="success">Copied</span><span aria-live="polite"></span></button></pre><p><strong>NOTE</strong>: You need to set the <a href="https://platform.openai.com/api-keys" rel="noopener" target="_blank"><code>OPENAI_API_KEY</code></a> environment variable for this to work.</p><div class="docsify-pagination-container">
<div class="pagination-item pagination-item--previous">
<a href="#/vision-models">
<div class="pagination-item-label">
<svg height="16" viewbox="0 0 10 16" width="10" xmlns="http://www.w3.org/2000/svg">
<polyline fill="none" points="8,2 2,8 8,14" vector-effect="non-scaling-stroke"></polyline>
</svg>
<span>Previous</span>
</div>
<div class="pagination-item-title">Vision Models</div>
<div class="pagination-item-subtitle"></div></a>
</div>
<div class="pagination-item pagination-item--next">
<a href="#/multimodal-embeddings">
<div class="pagination-item-label">
<span>Next</span>
<svg height="16" viewbox="0 0 10 16" width="10" xmlns="http://www.w3.org/2000/svg">
<polyline fill="none" points="2,2 8,8 2,14" vector-effect="non-scaling-stroke"></polyline>
</svg>
</div>
<div class="pagination-item-title">Multimodal Embeddings</div>
<div class="pagination-item-subtitle"></div></a>
</div>
</div></article>