<article class="markdown-section" id="main"><h2 id="parsing-json"><a class="anchor" data-id="parsing-json" href="#/parsing-json?id=parsing-json"><span>Parsing JSON</span></a></h2><p>JSON is everywhere—APIs, logs, configuration files—and its nested or large structure can challenge memory and processing. In this tutorial, we’ll explore tools to flatten, stream, and query JSON data efficiently.</p><p>For example, we’ll often need to process a multi-gigabyte log file from a web service where each record is a JSON object.</p><p><a href="https://youtu.be/1lxrb_ezP-g" rel="noopener" target="_blank"><img alt="JSON Parsing in Python" data-origin="https://i.ytimg.com/vi/1lxrb_ezP-g/sddefault.jpg" src="https://i.ytimg.com/vi/1lxrb_ezP-g/sddefault.jpg"/></a></p><p>This requires us to handle complex nested structures, large files that don’t fit in memory, or extract specific fields. Here are the key tools and techniques for efficient JSON parsing:</p>
<div class="table-wrapper">
<table id="_n7o0lkyox">
<thead><tr>
<th>Tool</th>
<th>Extract from JSON…</th>
<th>Why</th>
</tr>
</thead>
<tbody><tr>
<td><a href="#/parsing-json?id=command-line-json-processing-with-jq">jq</a></td>
<td>JSON in the shell</td>
<td>Quick data exploration and pipeline processing</td>
</tr>
<tr>
<td><a href="#/parsing-json?id=jmespath-queries">JMESPath</a></td>
<td>JSON in Python</td>
<td>Handle complex queries with a clean syntax</td>
</tr>
<tr>
<td><a href="#/parsing-json?id=streaming-with-ijson">ijson</a></td>
<td>JSON streams in Python</td>
<td>Parse streaming/large JSON files memory-efficiently</td>
</tr>
<tr>
<td><a href="#/parsing-json?id=pandas-json-columns">Pandas</a></td>
<td>JSON columns in Python</td>
<td>Fast analysis of structured data</td>
</tr>
<tr>
<td><a href="#/parsing-json?id=sql-json-functions">SQL JSON</a></td>
<td>JSON in databases</td>
<td>Combine structured and semi-structured data</td>
</tr>
<tr>
<td><a href="#/parsing-json?id=duckdb-json-processing">DuckDB</a></td>
<td>JSON anywhere</td>
<td>Fast analysis of JSON files / databases without loading to memory</td>
</tr>
</tbody>
</table>
</div><p><strong>Examples:</strong></p><ul><li>Use Pandas when you need to transform API responses into a DataFrame for further analysis.</li><li>Leverage ijson when dealing with huge JSON logs where memory is at a premium.</li><li>Apply jq for quick, iterative exploration directly in your terminal.</li></ul><p>Practice with these resources:</p><ul><li><a href="https://jsonpath.com/" rel="noopener" target="_blank">JSONPath Online Evaluator</a>: Test JSON queries</li><li><a href="https://jqplay.org/" rel="noopener" target="_blank">jq play</a>: Interactive jq query testing</li><li><a href="https://duckdb.org/docs/data/json" rel="noopener" target="_blank">DuckDB JSON Tutorial</a>: Learn DuckDB JSON functions</li></ul><h3 id="command-line-json-processing-with-jq"><a class="anchor" data-id="command-line-json-processing-with-jq" href="#/parsing-json?id=command-line-json-processing-with-jq"><span>Command-line JSON Processing with jq</span></a></h3><p><a href="https://jqlang.org/" rel="noopener" target="_blank">jq</a> is a versatile command-line tool for slicing, filtering, and transforming JSON. It excels in quick data exploration and can be integrated into shell scripts for automated data pipelines.</p><p><strong>Example:</strong> Sifting through server logs in JSON Lines format to extract error messages or aggregate metrics without launching a full-scale ETL process.</p><pre class="language-bash" data-lang="bash" v-pre=""><code class="lang-bash language-bash"><span class="token comment"># Extract specific fields from JSONL</span>
<span class="token function">cat</span> data.jsonl <span class="token operator">|</span> jq <span class="token parameter variable">-c</span> <span class="token string">'select(.type == "user") | {id, name}'</span>

<span class="token comment"># Transform JSON structure</span>
<span class="token function">cat</span> data.json <span class="token operator">|</span> jq <span class="token string">'.items[] | {name: .name, count: .details.count}'</span>

<span class="token comment"># Filter and aggregate</span>
<span class="token function">cat</span> events.jsonl <span class="token operator">|</span> jq <span class="token parameter variable">-s</span> <span class="token string">'group_by(.category) | map({category: .[0].category, count: length})'</span></code><button class="docsify-copy-code-button"><span class="label">Copy to clipboard</span><span aria-hidden="hidden" class="error">Error</span><span aria-hidden="hidden" class="success">Copied</span><span aria-live="polite"></span></button></pre><h3 id="jmespath-queries"><a class="anchor" data-id="jmespath-queries" href="#/parsing-json?id=jmespath-queries"><span>JMESPath Queries</span></a></h3><p><a href="https://jmespath.org/" rel="noopener" target="_blank">JMESPath</a> offers a declarative query language to extract and transform data from nested JSON structures without needing verbose code. It’s a neat alternative when you want to quickly pull out specific values or filter collections based on conditions.</p><p><strong>Example:</strong> Extracting user emails or filtering out inactive records from a complex JSON payload received from a cloud service.</p><pre class="language-python" data-lang="python" v-pre=""><code class="lang-python language-python"><span class="token keyword">import</span> jmespath

<span class="token comment"># Example queries</span>
data <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">"locations"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
        <span class="token punctuation">{</span><span class="token string">"name"</span><span class="token punctuation">:</span> <span class="token string">"Seattle"</span><span class="token punctuation">,</span> <span class="token string">"state"</span><span class="token punctuation">:</span> <span class="token string">"WA"</span><span class="token punctuation">,</span> <span class="token string">"info"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">"population"</span><span class="token punctuation">:</span> <span class="token number">737015</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token punctuation">{</span><span class="token string">"name"</span><span class="token punctuation">:</span> <span class="token string">"Portland"</span><span class="token punctuation">,</span> <span class="token string">"state"</span><span class="token punctuation">:</span> <span class="token string">"OR"</span><span class="token punctuation">,</span> <span class="token string">"info"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">"population"</span><span class="token punctuation">:</span> <span class="token number">652503</span><span class="token punctuation">}</span><span class="token punctuation">}</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">}</span>

<span class="token comment"># Find all cities with population &gt; 700000</span>
cities <span class="token operator">=</span> jmespath<span class="token punctuation">.</span>search<span class="token punctuation">(</span><span class="token string">"locations[?info.population &gt; `700000`].name"</span><span class="token punctuation">,</span> data<span class="token punctuation">)</span></code><button class="docsify-copy-code-button"><span class="label">Copy to clipboard</span><span aria-hidden="hidden" class="error">Error</span><span aria-hidden="hidden" class="success">Copied</span><span aria-live="polite"></span></button></pre><h3 id="streaming-with-ijson"><a class="anchor" data-id="streaming-with-ijson" href="#/parsing-json?id=streaming-with-ijson"><span>Streaming with ijson</span></a></h3><p>Loading huge JSON files all at once can quickly exhaust system memory. <a href="https://ijson.readthedocs.io/en/latest/" rel="noopener" target="_blank">ijson</a> lets you stream and process JSON incrementally. This method is ideal when your JSON file is too large or when you only need to work with part of the data.</p><p><strong>Example:</strong> Processing a continuous feed from an API that returns a large JSON array, such as sensor data or event logs, while filtering on the fly.</p><pre class="language-python" data-lang="python" v-pre=""><code class="lang-python language-python"><span class="token keyword">import</span> ijson

<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">process_large_json</span><span class="token punctuation">(</span>filepath<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">list</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Process a large JSON file without loading it entirely into memory."""</span>
    results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filepath<span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>
        <span class="token comment"># Stream objects under the 'items' key</span>
        parser <span class="token operator">=</span> ijson<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">,</span> <span class="token string">'items.item'</span><span class="token punctuation">)</span>
        <span class="token keyword">async</span> <span class="token keyword">for</span> item <span class="token keyword">in</span> parser<span class="token punctuation">:</span>
            <span class="token keyword">if</span> item<span class="token punctuation">[</span><span class="token string">'value'</span><span class="token punctuation">]</span> <span class="token operator">&gt;</span> <span class="token number">100</span><span class="token punctuation">:</span>  <span class="token comment"># Process conditionally</span>
                results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>item<span class="token punctuation">)</span>

    <span class="token keyword">return</span> results</code><button class="docsify-copy-code-button"><span class="label">Copy to clipboard</span><span aria-hidden="hidden" class="error">Error</span><span aria-hidden="hidden" class="success">Copied</span><span aria-live="polite"></span></button></pre><h3 id="pandas-json-columns"><a class="anchor" data-id="pandas-json-columns" href="#/parsing-json?id=pandas-json-columns"><span>Pandas JSON Columns</span></a></h3><p><a href="https://pandas.pydata.org/" rel="noopener" target="_blank">Pandas</a> makes it easy to work with tabular data that includes JSON strings. When you receive API data where one column holds nested JSON, flattening these structures lets you analyze and visualize the data using familiar DataFrame operations.</p><p><strong>Example:</strong> Flattening customer records stored as nested JSON in a CSV file to extract demographic details and spending patterns.</p><pre class="language-python" data-lang="python" v-pre=""><code class="lang-python language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

<span class="token comment"># Parse JSON strings in a column</span>
df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'json_col'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'{"name": "Alice", "age": 30}'</span><span class="token punctuation">,</span> <span class="token string">'{"name": "Bob", "age": 25}'</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
df<span class="token punctuation">[</span><span class="token string">'parsed'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'json_col'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>pd<span class="token punctuation">.</span>json_normalize<span class="token punctuation">)</span>

<span class="token comment"># Normalize nested JSON columns</span>
df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'data.csv'</span><span class="token punctuation">)</span>
df_normalized <span class="token operator">=</span> pd<span class="token punctuation">.</span>json_normalize<span class="token punctuation">(</span>
    df<span class="token punctuation">[</span><span class="token string">'nested_json'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>json<span class="token punctuation">.</span>loads<span class="token punctuation">)</span><span class="token punctuation">,</span>
    record_path<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'items'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token comment"># List of nested objects to unpack</span>
    meta<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'id'</span><span class="token punctuation">,</span> <span class="token string">'timestamp'</span><span class="token punctuation">]</span>      <span class="token comment"># Keep these columns from parent</span>
<span class="token punctuation">)</span></code><button class="docsify-copy-code-button"><span class="label">Copy to clipboard</span><span aria-hidden="hidden" class="error">Error</span><span aria-hidden="hidden" class="success">Copied</span><span aria-live="polite"></span></button></pre><h3 id="sql-json-functions"><a class="anchor" data-id="sql-json-functions" href="#/parsing-json?id=sql-json-functions"><span>SQL JSON Functions</span></a></h3><p><a href="https://en.wikipedia.org/wiki/SQL:2016" rel="noopener" target="_blank">SQL</a> supports built-in JSON functions allow you to query and manipulate JSON stored within relational databases.
These are implemented by most popular databases, including
<a href="https://www.sqlite.org/json1.html" rel="noopener" target="_blank">SQLite</a>,
<a href="https://www.postgresql.org/docs/current/functions-json.html" rel="noopener" target="_blank">PostgreSQL</a>, and
<a href="https://dev.mysql.com/doc/refman/8.4/en/json-function-reference.html" rel="noopener" target="_blank">MySQL</a>.
This is especially handy when you have a hybrid data model, combining structured tables with semi-structured JSON columns.</p><p><strong>Example:</strong> An application that stores user settings or application logs as JSON in a SQLite database, enabling quick lookups and modifications without external JSON parsing libraries.</p><pre class="language-sql" data-lang="sql" v-pre=""><code class="lang-sql language-sql"><span class="token keyword">SELECT</span>
    json_extract<span class="token punctuation">(</span><span class="token keyword">data</span><span class="token punctuation">,</span> <span class="token string">'$.name'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> name<span class="token punctuation">,</span>
    json_extract<span class="token punctuation">(</span><span class="token keyword">data</span><span class="token punctuation">,</span> <span class="token string">'$.details.age'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> age
<span class="token keyword">FROM</span> users
<span class="token keyword">WHERE</span> json_extract<span class="token punctuation">(</span><span class="token keyword">data</span><span class="token punctuation">,</span> <span class="token string">'$.active'</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token boolean">true</span></code><button class="docsify-copy-code-button"><span class="label">Copy to clipboard</span><span aria-hidden="hidden" class="error">Error</span><span aria-hidden="hidden" class="success">Copied</span><span aria-live="polite"></span></button></pre><h3 id="duckdb-json-processing"><a class="anchor" data-id="duckdb-json-processing" href="#/parsing-json?id=duckdb-json-processing"><span>DuckDB JSON Processing</span></a></h3><p><a href="https://duckdb.org/" rel="noopener" target="_blank">DuckDB</a> shines when analyzing JSON/JSONL files directly, making it a powerful tool for data analytics without the overhead of loading entire datasets into memory. Its SQL-like syntax simplifies exploratory analysis on nested data.</p><p><strong>Example:</strong> Performing ad-hoc analytics on streaming JSON logs from a web service, such as calculating average response times or aggregating user behavior metrics.</p><pre class="language-sql" data-lang="sql" v-pre=""><code class="lang-sql language-sql"><span class="token keyword">SELECT</span>
    json_extract_string<span class="token punctuation">(</span><span class="token keyword">data</span><span class="token punctuation">,</span> <span class="token string">'$.user.name'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> name<span class="token punctuation">,</span>
    <span class="token function">avg</span><span class="token punctuation">(</span>json_extract_float<span class="token punctuation">(</span><span class="token keyword">data</span><span class="token punctuation">,</span> <span class="token string">'$.metrics.value'</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> avg_value
<span class="token keyword">FROM</span> read_json_auto<span class="token punctuation">(</span><span class="token string">'data/*.jsonl'</span><span class="token punctuation">)</span>
<span class="token keyword">GROUP</span> <span class="token keyword">BY</span> <span class="token number">1</span>
<span class="token keyword">HAVING</span> avg_value <span class="token operator">&gt;</span> <span class="token number">100</span></code><button class="docsify-copy-code-button"><span class="label">Copy to clipboard</span><span aria-hidden="hidden" class="error">Error</span><span aria-hidden="hidden" class="success">Copied</span><span aria-live="polite"></span></button></pre><div class="docsify-pagination-container">
<div class="pagination-item pagination-item--previous">
<a href="#/profiling-data-with-python">
<div class="pagination-item-label">
<svg height="16" viewbox="0 0 10 16" width="10" xmlns="http://www.w3.org/2000/svg">
<polyline fill="none" points="8,2 2,8 8,14" vector-effect="non-scaling-stroke"></polyline>
</svg>
<span>Previous</span>
</div>
<div class="pagination-item-title">Profiling Data with Python</div>
<div class="pagination-item-subtitle"></div></a>
</div>
<div class="pagination-item pagination-item--next">
<a href="#/dbt">
<div class="pagination-item-label">
<span>Next</span>
<svg height="16" viewbox="0 0 10 16" width="10" xmlns="http://www.w3.org/2000/svg">
<polyline fill="none" points="2,2 8,8 2,14" vector-effect="non-scaling-stroke"></polyline>
</svg>
</div>
<div class="pagination-item-title">Data Transformation with dbt</div>
<div class="pagination-item-subtitle"></div></a>
</div>
</div></article>