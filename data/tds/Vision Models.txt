<article class="markdown-section" id="main"><h2 id="vision-models"><a class="anchor" data-id="vision-models" href="#/vision-models?id=vision-models"><span>Vision Models</span></a></h2><p><a href="https://youtu.be/FgT_Mk_bakQ" rel="noopener" target="_blank"><img alt="LLM Vision Models" data-origin="https://i.ytimg.com/vi_webp/FgT_Mk_bakQ/sddefault.webp" src="https://i.ytimg.com/vi_webp/FgT_Mk_bakQ/sddefault.webp"/></a></p><p>You’ll learn how to use LLMs to interpret images and extract useful information, covering:</p><ul><li><strong>Setting Up Vision Models</strong>: Integrate vision capabilities with LLMs using APIs like OpenAI’s Chat Completion.</li><li><strong>Sending Image URLs for Analysis</strong>: Pass URLs or base64-encoded images to LLMs for processing.</li><li><strong>Reading Image Responses</strong>: Get detailed textual descriptions of images, from scenic landscapes to specific objects like cricketers or bank statements.</li><li><strong>Extracting Data from Images</strong>: Convert extracted image data to various formats like Markdown tables or JSON arrays.</li><li><strong>Handling Model Hallucinations</strong>: Address inaccuracies in extraction results, understanding how different prompts can affect output quality.</li><li><strong>Cost Management for Vision Models</strong>: Adjust detail settings (e.g., “detail: low”) to balance cost and output precision.</li></ul><p>Here are the links used in the video:</p><ul><li><a href="https://colab.research.google.com/drive/1bK0b1XMrZWImtw01T1w9NGraDkiVi8mS" rel="noopener" target="_blank">Jupyter Notebook</a></li><li><a href="https://platform.openai.com/docs/api-reference/chat/create" rel="noopener" target="_blank">OpenAI Chat API Reference</a></li><li><a href="https://platform.openai.com/docs/guides/vision" rel="noopener" target="_blank">OpenAI Vision Guide</a></li><li><a href="https://drive.google.com/drive/folders/14MFc7XmGIUDU4-vbmF9305c1SSQrM-gR" rel="noopener" target="_blank">Sample images used</a></li></ul><p>Here is an example of how to analyze an image using the OpenAI API.</p><pre class="language-bash" data-lang="bash" v-pre=""><code class="lang-bash language-bash"><span class="token function">curl</span> https://api.openai.com/v1/chat/completions <span class="token punctuation">\</span>
  <span class="token parameter variable">-H</span> <span class="token string">"Content-Type: application/json"</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">-H</span> <span class="token string">"Authorization: Bearer <span class="token variable">$OPENAI_API_KEY</span>"</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">-d</span> <span class="token string">'{
    "model": "gpt-4o-mini",
    "messages": [
      {
        "role": "user",
        "content": [
          {"type": "text", "text": "What is in this image?"},
          {
            "type": "image_url",
            "detail": "low",
            "image_url": {"url": "https://upload.wikimedia.org/wikipedia/commons/3/34/Correlation_coefficient.png"}
          }
        ]
      }
    ]
  }'</span></code><button class="docsify-copy-code-button"><span class="label">Copy to clipboard</span><span aria-hidden="hidden" class="error">Error</span><span aria-hidden="hidden" class="success">Copied</span><span aria-live="polite"></span></button></pre><p>Let’s break down the request:</p><ul><li><code>curl https://api.openai.com/v1/chat/completions</code>: The API endpoint for text generation.</li><li><code>-H "Content-Type: application/json"</code>: The content type of the request.</li><li><code>-H "Authorization: Bearer $OPENAI_API_KEY"</code>: The API key for authentication.</li><li><code>-d</code>: The request body.<ul><li><code>"model": "gpt-4o-mini"</code>: The model to use for text generation.</li><li><code>"messages":</code>: The messages to send to the model.<ul><li><code>"role": "user"</code>: The role of the message.</li><li><code>"content":</code>: The content of the message.<ul><li><code>{"type": "text", "text": "What is in this image?"}</code>: The text message.</li><li><code>{"type": "image_url"}</code>: The image message.<ul><li><code>"detail": "low"</code>: The detail level of the image. <code>low</code> uses fewer tokens at lower detail. <code>high</code> uses more tokens for higher detail.</li><li><code>"image_url": {"url": "https://upload.wikimedia.org/wikipedia/commons/3/34/Correlation_coefficient.png"}</code>: The URL of the image.</li></ul></li></ul></li></ul></li></ul></li></ul><p>You can send images in a <a href="#/base64-image">base64 encoded format</a>, too. For example:</p><pre class="language-bash" data-lang="bash" v-pre=""><code class="lang-bash language-bash"><span class="token comment"># Download image and convert to base64 in one step</span>
<span class="token assign-left variable">IMAGE_BASE64</span><span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span><span class="token function">curl</span> <span class="token parameter variable">-s</span> <span class="token string">"https://upload.wikimedia.org/wikipedia/commons/3/34/Correlation_coefficient.png"</span> <span class="token operator">|</span> base64 <span class="token parameter variable">-w</span> <span class="token number">0</span><span class="token variable">)</span></span>

<span class="token comment"># Send to OpenAI API</span>
<span class="token function">curl</span> https://api.openai.com/v1/chat/completions <span class="token punctuation">\</span>
  <span class="token parameter variable">-H</span> <span class="token string">"Content-Type: application/json"</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">-H</span> <span class="token string">"Authorization: Bearer <span class="token variable">$OPENAI_API_KEY</span>"</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">-d</span> @- <span class="token operator">&lt;&lt;</span> <span class="token string">EOF
{
  "model": "gpt-4o-mini",
  "messages": [
    {
      "role": "user",
      "content": [
        {"type": "text", "text": "What is in this image?"},
        {
          "type": "image_url",
          "image_url": { "url": "data:image/png;base64,<span class="token variable">$IMAGE_BASE64</span>" }
        }
      ]
    }
  ]
}
EOF</span></code><button class="docsify-copy-code-button"><span class="label">Copy to clipboard</span><span aria-hidden="hidden" class="error">Error</span><span aria-hidden="hidden" class="success">Copied</span><span aria-live="polite"></span></button></pre><div class="docsify-pagination-container">
<div class="pagination-item pagination-item--previous">
<a href="#/base64-encoding">
<div class="pagination-item-label">
<svg height="16" viewbox="0 0 10 16" width="10" xmlns="http://www.w3.org/2000/svg">
<polyline fill="none" points="8,2 2,8 8,14" vector-effect="non-scaling-stroke"></polyline>
</svg>
<span>Previous</span>
</div>
<div class="pagination-item-title">Base 64 Encoding</div>
<div class="pagination-item-subtitle"></div></a>
</div>
<div class="pagination-item pagination-item--next">
<a href="#/embeddings">
<div class="pagination-item-label">
<span>Next</span>
<svg height="16" viewbox="0 0 10 16" width="10" xmlns="http://www.w3.org/2000/svg">
<polyline fill="none" points="2,2 8,8 2,14" vector-effect="non-scaling-stroke"></polyline>
</svg>
</div>
<div class="pagination-item-title">Embeddings</div>
<div class="pagination-item-subtitle"></div></a>
</div>
</div></article>