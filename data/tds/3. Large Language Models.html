<article class="markdown-section" id="main"><h1 id="large-language-models"><a class="anchor" data-id="large-language-models" href="#/large-language-models?id=large-language-models"><span>Large Language Models</span></a></h1><p>This module covers the practical usage of large language models (LLMs).</p><p><strong>LLMs incur a cost.</strong> For the May 2025 batch, use <a href="https://aipipe.org/" rel="noopener" target="_blank">aipipe.org</a> as a proxy.
Emails with <code>@ds.study.iitm.ac.in</code> get a <strong>$1 per calendar month</strong> allowance. (Don’t exceed that.)</p><p>Read the <a href="https://github.com/sanand0/aipipe" rel="noopener" target="_blank">AI Pipe documentation</a> to learn how to use it. But in short:</p><ol><li>Replace <code>OPENAI_BASE_URL</code>, i.e. <code>https://api.openai.com/v1</code> with <code>https://aipipe.org/openrouter/v1...</code> or <code>https://aipipe.org/openai/v1...</code></li><li>Replace <code>OPENAI_API_KEY</code> with the <a href="https://aipipe.org/login" rel="noopener" target="_blank"><code>AIPIPE_TOKEN</code></a></li><li>Replace model names, e.g. <code>gpt-4.1-nano</code>, with <code>openai/gpt-4.1-nano</code></li></ol><p>For example, let’s use <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-0-flash-lite" rel="noopener" target="_blank">Gemini 2.0 Flash Lite</a> via <a href="https://openrouter.ai/google/gemini-2.0-flash-lite-001" rel="noopener" target="_blank">OpenRouter</a> for chat completions and <a href="https://platform.openai.com/docs/models/text-embedding-3-small" rel="noopener" target="_blank">Text Embedding 3 Small</a> via <a href="https://platform.openai.com/docs/" rel="noopener" target="_blank">OpenAI</a> for embeddings:</p><pre class="language-bash" data-lang="bash" v-pre=""><code class="lang-bash language-bash"><span class="token function">curl</span> https://aipipe.org/openrouter/v1/chat/completions <span class="token punctuation">\</span>
  <span class="token parameter variable">-H</span> <span class="token string">"Content-Type: application/json"</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">-H</span> <span class="token string">"Authorization: Bearer <span class="token variable">$AIPIPE_TOKEN</span>"</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">-d</span> <span class="token string">'{
    "model": "google/gemini-2.0-flash-lite-001",
    "messages": [{ "role": "user", "content": "What is 2 + 2?"} }]
  }'</span>

<span class="token function">curl</span> https://aipipe.org/openai/v1/embeddings <span class="token punctuation">\</span>
  <span class="token parameter variable">-H</span> <span class="token string">"Content-Type: application/json"</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">-H</span> <span class="token string">"Authorization: Bearer <span class="token variable">$AIPIPE_TOKEN</span>"</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">-d</span> <span class="token string">'{ "model": "text-embedding-3-small", "input": "What is 2 + 2?" }'</span></code><button class="docsify-copy-code-button"><span class="label">Copy to clipboard</span><span aria-hidden="hidden" class="error">Error</span><span aria-hidden="hidden" class="success">Copied</span><span aria-live="polite"></span></button></pre><p>Or using <a href="https://llm.datasette.io/" rel="noopener" target="_blank"><code>llm</code></a>:</p><pre class="language-bash" data-lang="bash" v-pre=""><code class="lang-bash language-bash">llm keys <span class="token builtin class-name">set</span> openai <span class="token parameter variable">--value</span> <span class="token variable">$AIPIPE_TOKEN</span>

<span class="token builtin class-name">export</span> <span class="token assign-left variable">OPENAI_BASE_URL</span><span class="token operator">=</span>https://aipipe.org/openrouter/v1
llm <span class="token string">'What is 2 + 2?'</span> <span class="token parameter variable">-m</span> openrouter/google/gemini-2.0-flash-lite-001

<span class="token builtin class-name">export</span> <span class="token assign-left variable">OPENAI_BASE_URL</span><span class="token operator">=</span>https://aipipe.org/openai/v1
llm embed <span class="token parameter variable">-c</span> <span class="token string">'What is 2 + 2'</span> <span class="token parameter variable">-m</span> <span class="token number">3</span>-small</code><button class="docsify-copy-code-button"><span class="label">Copy to clipboard</span><span aria-hidden="hidden" class="error">Error</span><span aria-hidden="hidden" class="success">Copied</span><span aria-live="polite"></span></button></pre><p><strong>For a 50% discount</strong> (but slower speed), use <a href="https://platform.openai.com/docs/guides/flex-processing" rel="noopener" target="_blank">Flex processing</a> by adding <code>service_tier: "flex"</code> to your JSON request.</p><h2 id="ai-proxy-jan-2025"><a class="anchor" data-id="ai-proxy-jan-2025" href="#/large-language-models?id=ai-proxy-jan-2025"><span>AI Proxy - Jan 2025</span></a></h2><p>For the Jan 2025 batch, we had created API keys for everyone with an <code>iitm.ac.in</code> email to use <code>gpt-4o-mini</code> and <code>text-embedding-3-small</code>. Your usage is limited to <strong>$1 per calendar month</strong> for this course. Don’t exceed that.</p><p><strong>Use <a href="https://github.com/sanand0/aiproxy" rel="noopener" target="_blank">AI Proxy</a></strong> instead of OpenAI. Specifically:</p><ol><li>Replace your API to <code>https://api.openai.com/...</code> with <code>https://aiproxy.sanand.workers.dev/openai/...</code></li><li>Replace the <code>OPENAI_API_KEY</code> with the <code>AIPROXY_TOKEN</code> that someone will give you.</li></ol><div class="docsify-pagination-container">
<div class="pagination-item pagination-item--previous">
<a href="#/ollama">
<div class="pagination-item-label">
<svg height="16" viewbox="0 0 10 16" width="10" xmlns="http://www.w3.org/2000/svg">
<polyline fill="none" points="8,2 2,8 8,14" vector-effect="non-scaling-stroke"></polyline>
</svg>
<span>Previous</span>
</div>
<div class="pagination-item-title">Local LLMs: Ollama</div>
<div class="pagination-item-subtitle"></div></a>
</div>
<div class="pagination-item pagination-item--next">
<a href="#/prompt-engineering">
<div class="pagination-item-label">
<span>Next</span>
<svg height="16" viewbox="0 0 10 16" width="10" xmlns="http://www.w3.org/2000/svg">
<polyline fill="none" points="2,2 8,8 2,14" vector-effect="non-scaling-stroke"></polyline>
</svg>
</div>
<div class="pagination-item-title">Prompt engineering</div>
<div class="pagination-item-subtitle"></div></a>
</div>
</div></article>